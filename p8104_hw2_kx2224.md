p8104_hw2_kx2224
================
Kangyu Xu (kx2224)
2024-10-01

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(readxl)
library(haven)
library(janitor)
```

    ## 
    ## Attaching package: 'janitor'
    ## 
    ## The following objects are masked from 'package:stats':
    ## 
    ##     chisq.test, fisher.test

``` r
library(tidyr)
```

## Problem 1

### Part 1

``` r
# Read data
nyc_transit_data = read.csv("Dataset/NYC_Transit_Subway_Entrance_And_Exit_Data.csv")

# retain relative lines and colums and delete the repeated line
nyc_transit_cleaned = nyc_transit_data %>%
  select(Line, Station.Name, Station.Latitude, Station.Longitude, Route1:Route6, Entry, Vending, Entrance.Type, ADA)

nyc_transit_cleaned = nyc_transit_cleaned %>%
  mutate(Entry = ifelse(Entry == "YES", TRUE, FALSE)) %>%
  distinct()  
```

#### Short description

The NYC Transit Subway Entrance and Exit dataset contains information
about each entrance and exit of subway stations across New York City.
The variables include details such as the subway line (`Line`), the name
of the station (`Station Name`), the latitude and longitude of the
station (`Station Latitude`, `Station Longitude`), the routes served by
each station (`Routes Served`), whether entry is permitted at each
entrance (`Entry`), the type of vending machines available (`Vending`),
the type of entrance (`Entrance Type`), and whether the entrance is
ADA-compliant (`ADA`).

During the data cleaning process, unnecessary columns were removed,
retaining only the relevant fields such as station information and
accessibility features. Additionally, the `Entry` variable, which was
originally in character format (`YES`/`NO`), was converted into a
logical variable (`TRUE` for YES, `FALSE` for NO).

After cleaning, the dataset contains 684 rows and 14 columns.

In total, the dataset is tidy. Each variable is in its own column, and
each observation (an entrance or exit of a subway station) is
represented by its own row, making the dataset structured and ready for
analysis.

### Part 2

``` r
distinct_stations = nyc_transit_cleaned %>%
  distinct(Line, Station.Name) %>%
  nrow()

distinct_stations
```

    ## [1] 465

``` r
ada_compliant_stations = nyc_transit_cleaned %>%
  filter(ADA == TRUE) %>%
  distinct(Line, Station.Name) %>%
  nrow()

ada_compliant_stations
```

    ## [1] 84

``` r
proportion_no_vending_allow_entry = nyc_transit_cleaned %>%
  filter(Vending == "NO") %>%
  summarise(proportion = mean(Entry))

proportion_no_vending_allow_entry
```

    ##   proportion
    ## 1  0.3846154

In conclusion: 1. the number of distinct stations is 465 2. the number
of ADA compliant station is 84 3. the proportion is 0.3846

### Part 3

``` r
# Reformat data so that route number and route name are distinct variables
nyc_transit_expanded = nyc_transit_cleaned %>%
  mutate(Routes = paste(Route1, Route2, Route3, Route4, Route5, Route6, sep = ", ")) %>%
  separate_rows(Routes, sep = ", ") %>%
  filter(Routes != "")

# Count how many distinct stations serve the A train
a_train_stations = nyc_transit_expanded %>%
  filter(Routes == "A") %>%
  distinct(Station.Name)

distinct_a_train_stations = nrow(a_train_stations)
distinct_a_train_stations
```

    ## [1] 56

The number of distinct station of A train is 56.

``` r
# Count how many ADA compliant stations serve the A train
ada_compliant_a_train_stations = nyc_transit_expanded %>%
  filter(Routes == "A", ADA == TRUE) %>%
  distinct(Station.Name)

ada_compliant_a_train_stations_count = nrow(ada_compliant_a_train_stations)
ada_compliant_a_train_stations_count
```

    ## [1] 16

The number of ADA compliant is 16.

## Problem 2

``` r
sheet_names = excel_sheets("Dataset/202409 Trash Wheel Collection Data.xlsx")
sheet_names
```

    ## [1] "Mr. Trash Wheel"       "Professor Trash Wheel" "Captain Trash Wheel"  
    ## [4] "Gwynnda Trash Wheel"   "Sampling Methodology"  "Homes powered note"

``` r
mr_trash_wheel = read_excel("Dataset/202409 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel",na = c("NA", ".", "")) %>%
  janitor :: clean_names() %>%
  filter(!is.na(dumpster)) %>%
  select(-c(15, 16)) %>%
  mutate(sports_balls = as.integer(round(sports_balls)),
         year = as.integer(year),
         name = "mr")
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

``` r
# Read Prof and Gwy data
prof_trash_wheel = read_excel("Dataset/202409 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel",na = c("NA", ".", "")) %>%
  janitor :: clean_names() %>%
  filter(!is.na(dumpster)) %>%
  mutate(
         year = as.integer(year),
         name = 'prof')

gwy_trash_wheel = read_excel("Dataset/202409 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel",na = c("NA", ".", "")) %>%
  janitor :: clean_names() %>%
  filter(!is.na(dumpster)) %>%
  mutate(
         year = as.integer(year),
         name = 'gwy')
```

``` r
# Combine
trash_wheel = 
  bind_rows(mr_trash_wheel, prof_trash_wheel, gwy_trash_wheel) %>% 
  janitor::clean_names() %>% 
  relocate(name)
trash_wheel
```

    ## # A tibble: 1,033 × 15
    ##    name  dumpster month  year date                weight_tons volume_cubic_yards
    ##    <chr>    <dbl> <chr> <int> <dttm>                    <dbl>              <dbl>
    ##  1 mr           1 May    2014 2014-05-16 00:00:00        4.31                 18
    ##  2 mr           2 May    2014 2014-05-16 00:00:00        2.74                 13
    ##  3 mr           3 May    2014 2014-05-16 00:00:00        3.45                 15
    ##  4 mr           4 May    2014 2014-05-17 00:00:00        3.1                  15
    ##  5 mr           5 May    2014 2014-05-17 00:00:00        4.06                 18
    ##  6 mr           6 May    2014 2014-05-20 00:00:00        2.71                 13
    ##  7 mr           7 May    2014 2014-05-21 00:00:00        1.91                  8
    ##  8 mr           8 May    2014 2014-05-28 00:00:00        3.7                  16
    ##  9 mr           9 June   2014 2014-06-05 00:00:00        2.52                 14
    ## 10 mr          10 June   2014 2014-06-11 00:00:00        3.76                 18
    ## # ℹ 1,023 more rows
    ## # ℹ 8 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <int>, homes_powered <dbl>

``` r
total_weight_prof =  trash_wheel%>%
  filter(name == "prof") |>
  summarise(total_weight_prof = sum(weight_tons, na.rm = TRUE))

cig_butts_gwy = trash_wheel %>%
  filter(name == "gwy",
         month == "June",
         year == "2022") %>%
  summarise(cig_butts_gwy = sum(cigarette_butts, na.rm = TRUE))

cig_butts_gwy
```

    ## # A tibble: 1 × 1
    ##   cig_butts_gwy
    ##           <dbl>
    ## 1         18120

### Conlcusion

The final dataset concludes 1033 obeservations.

The key variables have weight_tons, volume_cubic_yards, plastic_bottles,
polystyrene, cigarette_butts, glass_bottles, plastic_bags, wrappers,
sports_balls, homes_powered.

The total weight collected by Professor Trash wheel is 246.74\` tons.

The number of cigarette butts collected by Gwynnda wheel is 18120.

## Problem 3

``` r
bakers = read_csv("Dataset/gbb_datasets/bakers.csv",na = c("NA", ".", ""),show_col_types = FALSE) %>% janitor::clean_names()
bakes = read_csv("Dataset/gbb_datasets/bakes.csv",na = c("NA", ".", ""),show_col_types = FALSE) %>% janitor::clean_names()
results = read_csv("Dataset/gbb_datasets/results.csv",na = c("NA", ".", ""),show_col_types = FALSE,skip = 2) %>% janitor::clean_names()
head(bakers)
```

    ## # A tibble: 6 × 5
    ##   baker_name       series baker_age baker_occupation   hometown                 
    ##   <chr>             <dbl>     <dbl> <chr>              <chr>                    
    ## 1 Ali Imdad             4        25 Charity worker     Saltley, Birmingham      
    ## 2 Alice Fevronia       10        28 Geography teacher  Essex                    
    ## 3 Alvin Magallanes      6        37 Nurse              Bracknell, Berkshire     
    ## 4 Amelia LeBruin       10        24 Fashion designer   Halifax                  
    ## 5 Andrew Smyth          7        25 Aerospace engineer Derby / Holywood, County…
    ## 6 Annetha Mills         1        30 Midwife            Essex

``` r
head(bakes)
```

    ## # A tibble: 6 × 5
    ##   series episode baker     signature_bake                           show_stopper
    ##    <dbl>   <dbl> <chr>     <chr>                                    <chr>       
    ## 1      1       1 Annetha   Light Jamaican Black Cakewith Strawberr… Red, White …
    ## 2      1       1 David     Chocolate Orange Cake                    Black Fores…
    ## 3      1       1 Edd       Caramel Cinnamon and Banana Cake         N/A         
    ## 4      1       1 Jasminder Fresh Mango and Passion Fruit Hummingbi… N/A         
    ## 5      1       1 Jonathan  Carrot Cake with Lime and Cream Cheese … Three Tiere…
    ## 6      1       1 Lea       Cranberry and Pistachio Cakewith Orange… Raspberries…

``` r
head(results)
```

    ## # A tibble: 6 × 5
    ##   series episode baker     technical result
    ##    <dbl>   <dbl> <chr>         <dbl> <chr> 
    ## 1      1       1 Annetha           2 IN    
    ## 2      1       1 David             3 IN    
    ## 3      1       1 Edd               1 IN    
    ## 4      1       1 Jasminder        NA IN    
    ## 5      1       1 Jonathan          9 IN    
    ## 6      1       1 Louise           NA IN

``` r
# Data clean
colnames(bakers)[1] = "baker"
bakers <- bakers %>%
  mutate(`baker` = sub(" .*", "", `baker`))
head(bakers)
```

    ## # A tibble: 6 × 5
    ##   baker   series baker_age baker_occupation   hometown                     
    ##   <chr>    <dbl>     <dbl> <chr>              <chr>                        
    ## 1 Ali          4        25 Charity worker     Saltley, Birmingham          
    ## 2 Alice       10        28 Geography teacher  Essex                        
    ## 3 Alvin        6        37 Nurse              Bracknell, Berkshire         
    ## 4 Amelia      10        24 Fashion designer   Halifax                      
    ## 5 Andrew       7        25 Aerospace engineer Derby / Holywood, County Down
    ## 6 Annetha      1        30 Midwife            Essex

``` r
# Data Check
bakes_mismatch = bakes %>% anti_join(bakers, by = "baker")
results_mismatch = results %>% anti_join(bakers, by = "baker")
bakes_mismatch
```

    ## # A tibble: 8 × 5
    ##   series episode baker    signature_bake                            show_stopper
    ##    <dbl>   <dbl> <chr>    <chr>                                     <chr>       
    ## 1      2       1 "\"Jo\"" Chocolate Orange CupcakesOrange and Card… Chocolate a…
    ## 2      2       2 "\"Jo\"" Caramelised Onion, Gruyere and Thyme Qui… Raspberry a…
    ## 3      2       3 "\"Jo\"" Stromboli flavored with Mozzarella, Ham,… Unknown     
    ## 4      2       4 "\"Jo\"" Lavender Biscuits                         Blueberry M…
    ## 5      2       5 "\"Jo\"" Salmon and Asparagus Pie                  Apple and R…
    ## 6      2       6 "\"Jo\"" Rum and Raisin Baked Cheesecake           Limoncello …
    ## 7      2       7 "\"Jo\"" Raspberry & Strawberry Mousse Cake        Pain Aux Ra…
    ## 8      2       8 "\"Jo\"" Raspberry and Blueberry Mille Feuille     Mini Victor…

``` r
results_mismatch
```

    ## # A tibble: 8 × 5
    ##   series episode baker  technical result    
    ##    <dbl>   <dbl> <chr>      <dbl> <chr>     
    ## 1      2       1 Joanne        11 IN        
    ## 2      2       2 Joanne        10 IN        
    ## 3      2       3 Joanne         1 IN        
    ## 4      2       4 Joanne         8 IN        
    ## 5      2       5 Joanne         6 IN        
    ## 6      2       6 Joanne         1 STAR BAKER
    ## 7      2       7 Joanne         3 IN        
    ## 8      2       8 Joanne         1 WINNER

``` r
# Combine data
data_combine = bakes %>%
  full_join(bakers, by=c("baker","series")) %>%
  right_join(results, by = c("baker","series","episode") ) %>%
  relocate(baker) %>% 
  relocate(baker_age, .after = baker) %>% 
  relocate(baker_occupation, .before = series)
head(data_combine)
```

    ## # A tibble: 6 × 10
    ##   baker    baker_age baker_occupation series episode signature_bake show_stopper
    ##   <chr>        <dbl> <chr>             <dbl>   <dbl> <chr>          <chr>       
    ## 1 Annetha         30 Midwife               1       1 Light Jamaica… Red, White …
    ## 2 David           31 Entrepreneur          1       1 Chocolate Ora… Black Fores…
    ## 3 Edd             24 Debt collector …      1       1 Caramel Cinna… N/A         
    ## 4 Jasmind…        45 Assistant Credi…      1       1 Fresh Mango a… N/A         
    ## 5 Jonathan        25 Research Analyst      1       1 Carrot Cake w… Three Tiere…
    ## 6 Lea             51 Retired               1       1 Cranberry and… Raspberries…
    ## # ℹ 3 more variables: hometown <chr>, technical <dbl>, result <chr>

``` r
# Output data
write.csv(data_combine, 
          file = "output_dats_Q3.csv", 
          row.names = FALSE)
```

### Data cleaning

I started by importing the three datasets: bakers.csv, bakes.csv, and
results.csv. I included some specific options to handle missing values
represented as “NA”, “.”, or empty strings. Additionally, I applied the
janitor::clean_names() function to ensure that the column names were
consistent and in lowercase, making the data easier to work with.

After importing, I cleaned the bakers dataset by adjusting the
baker_name column. My goal here was to simplify the names, so I used a
function to extract only the first name (i.e., everything before the
first space). This helped avoid issues during later merging, as some
entries only referred to bakers by their first names in the other
datasets.

Next, I performed a critical step: checking for mismatches between the
datasets. Specifically, I wanted to ensure that every baker in the bakes
and results datasets matched the bakers dataset. To do this, I used the
anti_join() function, which allowed me to identify any bakers that were
present in bakes or results but not in bakers.

In the bakes dataset, I found eight mismatches, all related to a baker
named “Jo”. Upon inspection, it seemed that there were issues with the
formatting of the baker’s name—quotes were included around “Jo”. In
contrast, the results dataset revealed that these entries referred to a
baker named “Joanne”. This discrepancy between “Jo” and “Joanne” was
important, as it indicated a data quality issue that needed to be
addressed to ensure consistency.

### Brief description

The final dataset contains detailed information about each baker and
their performance in the baking competition. It includes the following
columns:

    1.  baker: The first name of the baker.
    2.  baker_age: The age of the baker.
    3.  baker_occupation: The baker’s occupation.
    4.  series: The series (season) of the competition.
    5.  episode: The episode number within the series.
    6.  signature_bake: The name and description of the baker’s signature bake.
    7.  show_stopper: The name and description of the baker’s showstopper creation.
    8.  hometown: The baker’s hometown.
    9.  technical: The baker’s ranking in the technical challenge.
    10. result: The result of the episode (e.g., whether the baker was “IN” the competition, won, or became the “STAR BAKER”).

``` r
star_baker_winner = data_combine %>%
  filter(series >= 5 & series <= 10) %>%
  filter(result %in% c("STAR BAKER", "WINNER"))

star_baker_winner
```

    ## # A tibble: 60 × 10
    ##    baker   baker_age baker_occupation series episode signature_bake show_stopper
    ##    <chr>       <dbl> <chr>             <dbl>   <dbl> <chr>          <chr>       
    ##  1 Nancy          60 Retired Practic…      5       1 Coffee and Ha… "Jaffa Oran…
    ##  2 Richard        38 Builder               5       2 Rosemary Seed… "Pirates!"  
    ##  3 Luis           42 Graphic Designer      5       3 Opposites Att… "Roscón de …
    ##  4 Richard        38 Builder               5       4 Black Forest … "Tiramisu B…
    ##  5 Kate           41 Furniture Resto…      5       5 Rhubarb and C… "Rhubarb, P…
    ##  6 Chetna         35 Fashion Designer      5       6 Orange Savari… "Almond Liq…
    ##  7 Richard        38 Builder               5       7 Minted Lamb P… "Stair of É…
    ##  8 Richard        38 Builder               5       8 Fruit Swedish… "Rhubarb an…
    ##  9 Richard        38 Builder               5       9 Rose and Pist… "Hazelnut M…
    ## 10 Nancy          60 Retired Practic…      5      10 Apple and Lem… "Red Windmi…
    ## # ℹ 50 more rows
    ## # ℹ 3 more variables: hometown <chr>, technical <dbl>, result <chr>

``` r
summary_table = star_baker_winner %>%
  select(series, episode, baker, result) %>%
  arrange(series, episode)

summary_table
```

    ## # A tibble: 60 × 4
    ##    series episode baker   result    
    ##     <dbl>   <dbl> <chr>   <chr>     
    ##  1      5       1 Nancy   STAR BAKER
    ##  2      5       2 Richard STAR BAKER
    ##  3      5       3 Luis    STAR BAKER
    ##  4      5       4 Richard STAR BAKER
    ##  5      5       5 Kate    STAR BAKER
    ##  6      5       6 Chetna  STAR BAKER
    ##  7      5       7 Richard STAR BAKER
    ##  8      5       8 Richard STAR BAKER
    ##  9      5       9 Richard STAR BAKER
    ## 10      5      10 Nancy   WINNER    
    ## # ℹ 50 more rows

By analyzing this table, it can be found that some contestants may have
been “Star Baker” multiple times, which implies that they performed well
throughout the season and may have ended up winning the entire
competition. In particular, contestants who perform well in consecutive
episodes may be strong candidates for the eventual winner.

Sometimes there are surprises, such as contestants who are mediocre in
the first few episodes but end up winning the competition. Also, it may
come as a surprise that some contestants may only become “Star Baker” in
one episode and not be particularly prominent in other episodes.

``` r
viewer = read_csv("Dataset/gbb_datasets/viewers.csv",na = c("NA", ".", ""),show_col_types = FALSE) %>% 
  janitor::clean_names() %>%
  pivot_longer(
    cols = starts_with("series"),
    names_to = "series",
    values_to = "viewership",
    values_drop_na = TRUE  
  )

head(viewer, 10)
```

    ## # A tibble: 10 × 3
    ##    episode series    viewership
    ##      <dbl> <chr>          <dbl>
    ##  1       1 series_1        2.24
    ##  2       1 series_2        3.1 
    ##  3       1 series_3        3.85
    ##  4       1 series_4        6.6 
    ##  5       1 series_5        8.51
    ##  6       1 series_6       11.6 
    ##  7       1 series_7       13.6 
    ##  8       1 series_8        9.46
    ##  9       1 series_9        9.55
    ## 10       1 series_10       9.62

``` r
season_1 <- viewer %>% filter(series == "series_1")
season_5 <- viewer %>% filter(series == "series_5")

avg_viewership_season_1 <- season_1 %>% summarize(avg_viewership = mean(viewership, na.rm = TRUE))
avg_viewership_season_5 <- season_5 %>% summarize(avg_viewership = mean(viewership, na.rm = TRUE))

# Output the averages
avg_viewership_season_1
```

    ## # A tibble: 1 × 1
    ##   avg_viewership
    ##            <dbl>
    ## 1           2.77

``` r
avg_viewership_season_5
```

    ## # A tibble: 1 × 1
    ##   avg_viewership
    ##            <dbl>
    ## 1           10.0

So the average viewership of season 1 is 2.77. The average viewership of
season 5 is 10.04
